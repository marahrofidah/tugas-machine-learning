{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import yaml\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"blur a single image on CPU\"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        radias = kernel_size // 2\n",
    "        kernel_size = radias * 2 + 1\n",
    "        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n",
    "                                stride=1, padding=0, bias=False, groups=3)\n",
    "        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n",
    "                                stride=1, padding=0, bias=False, groups=3)\n",
    "        self.k = kernel_size\n",
    "        self.r = radias\n",
    "\n",
    "        self.blur = nn.Sequential(\n",
    "            nn.ReflectionPad2d(radias),\n",
    "            self.blur_h,\n",
    "            self.blur_v\n",
    "        )\n",
    "\n",
    "        self.pil_to_tensor = transforms.ToTensor()\n",
    "        self.tensor_to_pil = transforms.ToPILImage()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.pil_to_tensor(img).unsqueeze(0)\n",
    "\n",
    "        sigma = np.random.uniform(0.1, 2.0)\n",
    "        x = np.arange(-self.r, self.r + 1)\n",
    "        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n",
    "        x = x / x.sum()\n",
    "        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n",
    "\n",
    "        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n",
    "        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img = self.blur(img)\n",
    "            img = img.squeeze()\n",
    "\n",
    "        img = self.tensor_to_pil(img)\n",
    "\n",
    "        return img\n",
    "        \n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def save_config_file(model_checkpoints_folder, args):\n",
    "    if not os.path.exists(model_checkpoints_folder):\n",
    "        os.makedirs(model_checkpoints_folder)\n",
    "        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n",
    "            yaml.dump(args, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class SimCLR(object):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args = kwargs['args']\n",
    "        self.model = kwargs['model'].to(self.args.device)\n",
    "        self.optimizer = kwargs['optimizer']\n",
    "        self.scheduler = kwargs['scheduler']\n",
    "        # self.writer = SummaryWriter()\n",
    "        # logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
    "\n",
    "        os.makedirs(self.args.log_dir, exist_ok=True)\n",
    "        logging.basicConfig(filename=os.path.join(self.args.log_dir, 'training.log'),\n",
    "                            level=logging.INFO,\n",
    "                            format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "        self.csv_log_path = os.path.join(self.args.log_dir, 'metrics.csv')\n",
    "        with open(self.csv_log_path, mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['step', 'loss', 'acc_top1', 'acc_top5', 'learning_rate'])\n",
    "\n",
    "        \n",
    "\n",
    "    def info_nce_loss(self, features):\n",
    "\n",
    "        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.args.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        # assert similarity_matrix.shape == (\n",
    "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)\n",
    "\n",
    "        logits = logits / self.args.temperature\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self, train_loader):\n",
    "\n",
    "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
    "\n",
    "        # save config file\n",
    "        # save_config_file(self.writer.log_dir, self.args)\n",
    "\n",
    "        n_iter = 0\n",
    "        best_top1 = 0.0  \n",
    "        logging.info(f\"Start SimCLR training for {self.args.epochs} epochs.\")\n",
    "\n",
    "        for epoch_counter in range(self.args.epochs):\n",
    "            for images, _ in tqdm(train_loader):\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.args.device)\n",
    "\n",
    "                with autocast(enabled=self.args.fp16_precision):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                if n_iter % self.args.log_every_n_steps == 0:\n",
    "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                    lr = self.scheduler.get_last_lr()[0]\n",
    "\n",
    "                    print(f\"[Epoch {epoch_counter+1}] Step {n_iter}: Loss={loss:.4f}, Top1={top1[0]:.2f}%, Top5={top5[0]:.2f}%, LR={lr:.6f}\")\n",
    "\n",
    "\n",
    "                    # File log\n",
    "                    with open(self.csv_log_path, mode='a', newline='') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow([n_iter, loss.item(), top1[0].item(), top5[0].item(), lr])\n",
    "\n",
    "                    if top1[0].item() > best_top1:\n",
    "                        best_top1 = top1[0].item()\n",
    "                        best_ckpt_path = os.path.join(self.args.log_dir, 'checkpoint_best.pth')\n",
    "                        save_checkpoint({\n",
    "                            'epoch': epoch_counter + 1,\n",
    "                            'arch': self.args.arch,\n",
    "                            'state_dict': self.model.state_dict(),\n",
    "                            'optimizer': self.optimizer.state_dict(),\n",
    "                            'best_top1': best_top1\n",
    "                        }, is_best=True, filename=best_ckpt_path)\n",
    "                        logging.info(f\"New best model saved with Top1={best_top1:.2f}% at epoch {epoch_counter+1}, step {n_iter}\")\n",
    "\n",
    "                    \n",
    "\n",
    "                n_iter += 1\n",
    "\n",
    "            # warmup for the first 10 epochs\n",
    "            if epoch_counter >= 10:\n",
    "                self.scheduler.step()\n",
    "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "\n",
    "        logging.info(\"Training has finished.\")\n",
    "        # save model checkpoints\n",
    "        checkpoint_name = os.path.join(self.args.log_dir, f'checkpoint_{self.args.epochs:04d}.pth.tar')\n",
    "        \n",
    "        save_checkpoint({\n",
    "            'epoch': self.args.epochs,\n",
    "            'arch': self.args.arch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }, is_best=False, filename=checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BaseSimCLRException(Exception):\n",
    "    \"\"\"Base exception\"\"\"\n",
    "\n",
    "\n",
    "class InvalidBackboneError(BaseSimCLRException):\n",
    "    \"\"\"Raised when the choice of backbone Convnet is invalid.\"\"\"\n",
    "\n",
    "\n",
    "class InvalidDatasetSelection(BaseSimCLRException):\n",
    "    \"\"\"Raised when the choice of dataset is invalid.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ContrastiveLearningViewGenerator(object):\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, n_views=2):\n",
    "        self.base_transform = base_transform\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transform(x) for i in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class ContrastiveLearningDataset:\n",
    "    def __init__(self, root_folder):\n",
    "        self.root_folder = root_folder\n",
    "\n",
    "    @staticmethod\n",
    "    def get_simclr_pipeline_transform(size, s=1):\n",
    "        \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "        color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                              transforms.RandomGrayscale(p=0.2),\n",
    "                                              transforms.RandomApply([transforms.RandomAffine(degrees=30)], p=0.3),  # 🔥 MODIF 1\n",
    "                                              transforms.RandomSolarize(threshold=128, p=0.2),  # 🔥 MODIF 2\n",
    "                                              GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                                              transforms.ToTensor()])\n",
    "        return data_transforms\n",
    "\n",
    "    def get_dataset(self, name, n_views):\n",
    "        valid_datasets = {\n",
    "                        'cifar10': lambda: datasets.CIFAR10(self.root_folder, train=True,\n",
    "                                                          transform=ContrastiveLearningViewGenerator(\n",
    "                                                              self.get_simclr_pipeline_transform(32),\n",
    "                                                              n_views),\n",
    "                                                          download=True),\n",
    "                        'stl10': lambda: datasets.STL10(self.root_folder, split='unlabeled',\n",
    "                                                      transform=ContrastiveLearningViewGenerator(\n",
    "                                                          self.get_simclr_pipeline_transform(96),\n",
    "                                                          n_views),\n",
    "                                                      download=True),\n",
    "                        'tinyimagenet' : lambda: ImageFolder(\n",
    "                            root=os.path.join(self.root_folder, 'tiny-imagenet-200', 'train'),\n",
    "                            transform=ContrastiveLearningViewGenerator(\n",
    "                                self.get_simclr_pipeline_transform(64),  \n",
    "                                n_views))\n",
    "                        }\n",
    "\n",
    "        try:\n",
    "            dataset_fn = valid_datasets[name]\n",
    "        except KeyError:\n",
    "            raise InvalidDatasetSelection()\n",
    "        else:\n",
    "            return dataset_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "\n",
    "class ResNetSimCLR(nn.Module):\n",
    "\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super(ResNetSimCLR, self).__init__()\n",
    "        self.resnet_dict = {\"resnet18\": models.resnet18(weights=None, num_classes=out_dim),\n",
    "                             \"resnet34\": models.resnet34(weights=None, num_classes=out_dim),  # 🔥 MODIF 3\n",
    "                            \"resnet50\": models.resnet50(weights=None, num_classes=out_dim)}\n",
    "\n",
    "        self.backbone = self._get_basemodel(base_model)\n",
    "        dim_mlp = self.backbone.fc.in_features\n",
    "        \n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(dim_mlp, dim_mlp),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_mlp, dim_mlp // 2),  # 🔥 MODIF 4\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_mlp // 2, out_dim)\n",
    "        )\n",
    "    def _get_basemodel(self, model_name):\n",
    "        try:\n",
    "            model = self.resnet_dict[model_name]\n",
    "        except KeyError:\n",
    "            raise InvalidBackboneError(\n",
    "                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n",
    "        else:\n",
    "            return model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "args = SimpleNamespace()\n",
    "args.device = torch.device('cuda')\n",
    "args.data = '/kaggle/input/tiny-imagenet/tiny-imagenet-200'\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "args.dataset_name = 'tinyimagenet'\n",
    "args.n_views = 2\n",
    "args.batch_size = 256\n",
    "args.out_dim = 128\n",
    "args.lr = 0.0003\n",
    "args.weight_decay = 1e-4\n",
    "args.arch = 'resnet18'\n",
    "args.workers = 2\n",
    "args.gpu_index = 0\n",
    "args.log_dir = '/kaggle/working/logs/simclr'\n",
    "args.fp16_precision = True\n",
    "args.epochs = 50\n",
    "args.temperature = 0.07\n",
    "args.seed = 1\n",
    "args.log_every_n_steps = 100\n",
    "dataset = ContrastiveLearningDataset(args.data)\n",
    "\n",
    "train_dataset = dataset.get_dataset(args.dataset_name, args.n_views)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "model = ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                       last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with torch.cuda.device(args.gpu_index):\n",
    "    simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "    simclr.train(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSV log yang sudah diisi selama training\n",
    "log_df = pd.read_csv(os.path.join(args.log_dir, 'metrics.csv'))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(log_df['step'], log_df['loss'], label=\"Training Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"SimCLR Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE Visualisasi Representasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Ambil batch dari data\n",
    "data_iter = iter(train_loader)\n",
    "images, _ = next(data_iter)\n",
    "images = torch.cat(images, dim=0).to(args.device)\n",
    "\n",
    "# Ambil fitur dari backbone\n",
    "features = model.backbone(images).detach().cpu().numpy()\n",
    "\n",
    "# t-SNE reduce ke 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "features_2d = tsne.fit_transform(features)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(features_2d[:,0], features_2d[:,1], s=5, alpha=0.7)\n",
    "plt.title(\"t-SNE of SimCLR Representations\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 56828,
     "sourceId": 109264,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
